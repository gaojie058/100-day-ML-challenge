{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初学者的TensorFlow教程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "#载入Tensorflow\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入准备好的MNIST数据集。将样本从整数转换为浮点数:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 145 255 211  31   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  32 237 253 252  71   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 175 253 252  71   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 144 253 252  71   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  16 191 253 252  71   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  26 221 253 252 124  31   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 125 253 252 252 108   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 253 252 252 108   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 255 253 253 108   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 253 252 252 108   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 253 252 252 108   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 253 252 252 108   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 255 253 253 170   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 253 252 252 252  42\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 149 252 252 252 144\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 109 252 252 252 144\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 218 253 253 255\n",
      "   35   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0 175 252 252 253\n",
      "   35   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  73 252 252 253\n",
      "   35   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  31 211 252 253\n",
      "   35   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "plt.imshow(x_train[6])\n",
    "print(y_train[6])\n",
    "print(x_train[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0 # map each number between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将模型的各层堆叠起来，以搭建tf.keras.Sequential模型。为训练选择优化器和损失函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, 28)), # The image is 28x28 输入层\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'), # 128 neurons 隐藏层\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax') # Last layers have ten neurons, because there are ten kinds of clothes. 输出层\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练并验证模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0646 - accuracy: 0.9792\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0602 - accuracy: 0.9804\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0531 - accuracy: 0.9822\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0503 - accuracy: 0.9841\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0440 - accuracy: 0.9859\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0422 - accuracy: 0.9862s - l\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 0.0396 - accuracy: 0.9866\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0366 - accuracy: 0.9880\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.0341 - accuracy: 0.9886\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0330 - accuracy: 0.9888\n",
      "10000/10000 - 0s - loss: 0.0696 - accuracy: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06957913205295918, 0.9823]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 10)\n",
    "model.evaluate(x_test, y_test, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在这个照片分类器的准确度已经达到98%。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('loss')<0.02):\n",
    "            print(\"\\nLoss is low so cancelling training!\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0269 - accuracy: 0.9905\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 0.0255 - accuracy: 0.9913s\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0258 - accuracy: 0.9910\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 3s 45us/sample - loss: 0.0241 - accuracy: 0.9917\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 0.0240 - accuracy: 0.9920\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13d8183d0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = myCallback()\n",
    "model.fit(x_train, y_train, epochs=5, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "# 网络层\n",
    "\n",
    "### 关于Keras层\n",
    "- 所有层对象都有\n",
    "   - layer.get_weights(): 返回层的权重\n",
    "   - layer.set_weights(weights): 从numpy array中将权重加载到该层中\n",
    "   - layer.get_config(): 返回当前层配置信息的字典，层也可以借由配置信息重构\n",
    "- layer = Dense(32)\n",
    "\n",
    "\n",
    "\n",
    "后面待补充"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n",
    "# TensorFlow 2.0实践系列课程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "#载入Tensorflow\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A primer in machine learning\n",
    "- 深度学习是机器学习的进一步发展\n",
    "- 深度学习主要是依靠神经网络\n",
    "- TensorFlow中的一个API是Keras\n",
    "- keras使得定义神经网络变得容易\n",
    "- a neural network is basically a set of function which can learn patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Dense(units=1, input_shape=[1])]) \n",
    "model.compile(optimizer = 'sgd', loss = 'mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the simplest neural network with only one neural\n",
    "- use **Dense** to define a layer of connected neurons\n",
    "- **a single neuron**: only one dense here, so there's only one layer, one unit in it\n",
    "- **sequence**: Successive layers are defined in sequence, hence the word Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.array([-1.0, 0.0, 1.0, 2.0, 3.0, 4.0], dtype = float)\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6 samples\n",
      "Epoch 1/20\n",
      "6/6 [==============================] - 0s 602us/sample - loss: 0.7043\n",
      "Epoch 2/20\n",
      "6/6 [==============================] - 0s 237us/sample - loss: 0.6897\n",
      "Epoch 3/20\n",
      "6/6 [==============================] - 0s 244us/sample - loss: 0.6755\n",
      "Epoch 4/20\n",
      "6/6 [==============================] - 0s 321us/sample - loss: 0.6616\n",
      "Epoch 5/20\n",
      "6/6 [==============================] - 0s 265us/sample - loss: 0.6480\n",
      "Epoch 6/20\n",
      "6/6 [==============================] - 0s 421us/sample - loss: 0.6347\n",
      "Epoch 7/20\n",
      "6/6 [==============================] - 0s 443us/sample - loss: 0.6216\n",
      "Epoch 8/20\n",
      "6/6 [==============================] - 0s 492us/sample - loss: 0.6088\n",
      "Epoch 9/20\n",
      "6/6 [==============================] - 0s 280us/sample - loss: 0.5963\n",
      "Epoch 10/20\n",
      "6/6 [==============================] - 0s 286us/sample - loss: 0.5841\n",
      "Epoch 11/20\n",
      "6/6 [==============================] - 0s 411us/sample - loss: 0.5721\n",
      "Epoch 12/20\n",
      "6/6 [==============================] - 0s 352us/sample - loss: 0.5603\n",
      "Epoch 13/20\n",
      "6/6 [==============================] - 0s 469us/sample - loss: 0.5488\n",
      "Epoch 14/20\n",
      "6/6 [==============================] - 0s 313us/sample - loss: 0.5375\n",
      "Epoch 15/20\n",
      "6/6 [==============================] - 0s 743us/sample - loss: 0.5265\n",
      "Epoch 16/20\n",
      "6/6 [==============================] - 0s 453us/sample - loss: 0.5157\n",
      "Epoch 17/20\n",
      "6/6 [==============================] - 0s 428us/sample - loss: 0.5051\n",
      "Epoch 18/20\n",
      "6/6 [==============================] - 0s 229us/sample - loss: 0.4947\n",
      "Epoch 19/20\n",
      "6/6 [==============================] - 0s 352us/sample - loss: 0.4845\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 393us/sample - loss: 0.4746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x12debce10>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(xs, ys, epochs = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16.983816]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**two main reasons:**\n",
    "- very little data. There is very high probability that Y=19\n",
    "- neural network try to figure out the answers for everything, they deal in probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fashion MNIST dataset**\n",
    "- 70k Images\n",
    "- 10 Categories\n",
    "- Images are 28x28\n",
    "- Can train a neural net!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
